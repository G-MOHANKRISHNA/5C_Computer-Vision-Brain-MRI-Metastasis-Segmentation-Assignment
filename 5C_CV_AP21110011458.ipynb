{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Ak31ZZhX0wf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "gY1BUEk6Y04J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths\n",
        "IMAGE_DIR = r'/content/C:/Users/User/Downloads/Data/Data/images'\n",
        "MASK_DIR = r'/content/C:\\Users\\User\\Downloads\\Data\\Data/masks'\n",
        "\n",
        "# Image dimensions\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "IMG_CHANNELS = 1  # Assuming grayscale MRI images\n",
        "\n",
        "# Split ratio\n",
        "TRAIN_SIZE = 0.8\n"
      ],
      "metadata": {
        "id": "C5CfvYBglyo9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(image_dir, mask_dir, img_size=(256, 256)):\n",
        "    image_paths = sorted(glob(os.path.join(image_dir, \"*.png\")))  # Adjust extension if necessary\n",
        "    mask_paths = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n",
        "\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "        # Ensure both image and mask exist\n",
        "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
        "            # Read image in grayscale\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, img_size)\n",
        "            images.append(img)\n",
        "\n",
        "            # Read mask in grayscale\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if mask is None:\n",
        "                continue\n",
        "            mask = cv2.resize(mask, img_size)\n",
        "            masks.append(mask)\n",
        "\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "\n",
        "    # Expand dims to add channel axis\n",
        "    images = np.expand_dims(images, axis=-1)\n",
        "    masks = np.expand_dims(masks, axis=-1)\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "images, masks = load_images(IMAGE_DIR, MASK_DIR, img_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "print(f'Total images: {len(images)}, Total masks: {len(masks)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W6hJtk5mXUG",
        "outputId": "3569cad1-b430-43b4-f734-b90e83a7370e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 0, Total masks: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_clahe(images, clip_limit=2.0, tile_grid_size=(8,8)):\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "    enhanced_images = []\n",
        "    for img in images:\n",
        "        img = img.squeeze()  # Remove channel dimension\n",
        "        enhanced = clahe.apply(img)\n",
        "        enhanced_images.append(enhanced)\n",
        "    enhanced_images = np.array(enhanced_images)\n",
        "    enhanced_images = np.expand_dims(enhanced_images, axis=-1)\n",
        "    return enhanced_images\n",
        "\n",
        "enhanced_images = apply_clahe(images)\n"
      ],
      "metadata": {
        "id": "MYBK5YaCmZfq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(images, masks):\n",
        "    images = images.astype('float32') / 255.0\n",
        "    masks = masks.astype('float32') / 255.0\n",
        "    masks = np.round(masks)  # Ensure masks are binary\n",
        "    return images, masks\n",
        "\n",
        "images, masks = normalize(enhanced_images, masks)\n"
      ],
      "metadata": {
        "id": "Fgb_7LpVmeJT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation\n",
        "data_gen_args = dict(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.10,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "# Fit the generators if needed\n",
        "# image_datagen.fit(images, augment=True, seed=42)\n",
        "# mask_datagen.fit(masks, augment=True, seed=42)\n"
      ],
      "metadata": {
        "id": "8v20SqDkmm9U"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the split ratio\n",
        "TRAIN_SIZE = 0.8  # 80% training, 20% testing\n",
        "\n",
        "# Perform the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    train_size=TRAIN_SIZE,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "_skrKEiJqgxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, backend as K\n"
      ],
      "metadata": {
        "id": "PhmRHgkZqs_o"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "HpS4fi9AkZ9Y"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = layers.Conv2D(num_filters, 3, activation='relu', padding='same')(inputs)\n",
        "    x = layers.Conv2D(num_filters, 3, activation='relu', padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def nested_unet(input_shape=(256, 256, 1), num_classes=1, depth=4, filters=64):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Nested U-Net architecture\n",
        "    # Implementation based on U-Net++ paper\n",
        "\n",
        "    # Initialize dictionaries to store nodes\n",
        "    conv = {}\n",
        "    pool = {}\n",
        "    upsample = {}\n",
        "    concat = {}\n",
        "\n",
        "    # Encoder path\n",
        "    conv[0][0] = conv_block(inputs, filters)\n",
        "    pool[0] = layers.MaxPooling2D((2, 2))(conv[0][0])\n",
        "\n",
        "    conv[1][0] = conv_block(pool[0], filters*2)\n",
        "    pool[1] = layers.MaxPooling2D((2, 2))(conv[1][0])\n",
        "\n",
        "    conv[2][0] = conv_block(pool[1], filters*4)\n",
        "    pool[2] = layers.MaxPooling2D((2, 2))(conv[2][0])\n",
        "\n",
        "    conv[3][0] = conv_block(pool[2], filters*8)\n",
        "    pool[3] = layers.MaxPooling2D((2, 2))(conv[3][0])\n",
        "\n",
        "    conv[4][0] = conv_block(pool[3], filters*16)\n",
        "\n",
        "    # Decoder path\n",
        "    for i in range(1, depth):\n",
        "        for j in range(depth - i):\n",
        "            upsample[j + 1] = layers.UpSampling2D((2,2))(conv[j +1][i -1])\n",
        "            concat[j][i] = layers.Concatenate()([upsample[j +1], conv[j][i -1]])\n",
        "            conv[j][i] = conv_block(concat[j][i], filters * (2 ** (j +1)))\n",
        "\n",
        "    # Final output\n",
        "    outputs = layers.Conv2D(num_classes, (1,1), activation='sigmoid')(conv[0][depth -1])\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "NzxgrTR5qyDU"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_block(x, g, inter_channels):\n",
        "    theta_x = layers.Conv2D(inter_channels, kernel_size=1, strides=1, padding='same')(x)\n",
        "    phi_g = layers.Conv2D(inter_channels, kernel_size=1, strides=1, padding='same')(g)\n",
        "    add_xg = layers.Add()([theta_x, phi_g])\n",
        "    act_xg = layers.Activation('relu')(add_xg)\n",
        "    psi = layers.Conv2D(1, kernel_size=1, strides=1, padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    upsample_psi = layers.UpSampling2D(size=(x.shape[1] // sigmoid_xg.shape[1], x.shape[2] // sigmoid_xg.shape[2]))(sigmoid_xg)\n",
        "    y = layers.Multiply()([x, upsample_psi])\n",
        "    return y\n",
        "\n",
        "def attention_unet(input_shape=(256,256,1), num_classes=1):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = conv_block(inputs, 64)\n",
        "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
        "\n",
        "    c2 = conv_block(p1, 128)\n",
        "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
        "\n",
        "    c3 = conv_block(p2, 256)\n",
        "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
        "\n",
        "    c4 = conv_block(p3, 512)\n",
        "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
        "\n",
        "    # Bridge\n",
        "    c5 = conv_block(p4, 1024)\n",
        "\n",
        "    # Decoder with Attention\n",
        "    a4 = attention_block(c4, c5, 512)\n",
        "    up4 = layers.UpSampling2D((2,2))(c5)\n",
        "    up4 = layers.Concatenate()([up4, a4])\n",
        "    c6 = conv_block(up4, 512)\n",
        "\n",
        "    a3 = attention_block(c3, c6, 256)\n",
        "    up3 = layers.UpSampling2D((2,2))(c6)\n",
        "    up3 = layers.Concatenate()([up3, a3])\n",
        "    c7 = conv_block(up3, 256)\n",
        "\n",
        "    a2 = attention_block(c2, c7, 128)\n",
        "    up2 = layers.UpSampling2D((2,2))(c7)\n",
        "    up2 = layers.Concatenate()([up2, a2])\n",
        "    c8 = conv_block(up2, 128)\n",
        "\n",
        "    a1 = attention_block(c1, c8, 64)\n",
        "    up1 = layers.UpSampling2D((2,2))(c8)\n",
        "    up1 = layers.Concatenate()([up1, a1])\n",
        "    c9 = conv_block(up1, 64)\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, (1,1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "AfxNK0aRq0zw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Nested U-Net\n",
        "unet_plus = nested_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "unet_plus.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coef])\n",
        "\n",
        "# Compile Attention U-Net\n",
        "att_unet = attention_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "att_unet.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coef])\n"
      ],
      "metadata": {
        "id": "UW5Lb5Vcq-Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, monitor='val_dice_coef'),\n",
        "    EarlyStopping(monitor='val_dice_coef', patience=10, verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "Rn4Lkp4_rGuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "\n",
        "# Train Nested U-Net\n",
        "history_unet_plus = unet_plus.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Train Attention U-Net\n",
        "history_att_unet = att_unet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "IiIGn98-rLvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Nested U-Net\n",
        "score_unet_plus = unet_plus.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Nested U-Net Dice Coefficient: {score_unet_plus[1]}')\n",
        "\n",
        "# Evaluate Attention U-Net\n",
        "score_att_unet = att_unet.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Attention U-Net Dice Coefficient: {score_att_unet[1]}')\n"
      ],
      "metadata": {
        "id": "b1Y_PEWnrMcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if score_unet_plus[1] > score_att_unet[1]:\n",
        "    best_model = unet_plus\n",
        "    best_model_name = 'Nested U-Net'\n",
        "else:\n",
        "    best_model = att_unet\n",
        "    best_model_name = 'Attention U-Net'\n",
        "\n",
        "print(f'Best Model: {best_model_name} with Dice Coefficient: {max(score_unet_plus[1], score_att_unet[1])}')\n"
      ],
      "metadata": {
        "id": "WPqgqSVZrQj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save('best_metastasis_segmentation_model.h5')\n"
      ],
      "metadata": {
        "id": "HQvbomHjrSjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastapi uvicorn tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ZJkTmSrT_O",
        "outputId": "2df7aeff-4dd6-4e45-b042-1f4d81385d37"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.39.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.0 h11-0.14.0 starlette-0.38.6 uvicorn-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "import uvicorn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the best model\n",
        "model = tf.keras.models.load_model('best_metastasis_segmentation_model.h5', compile=False)\n",
        "\n",
        "def preprocess_image(image_bytes, img_size=(256, 256)):\n",
        "    # Read image\n",
        "    image = Image.open(io.BytesIO(image_bytes)).convert('L')  # Convert to grayscale\n",
        "    image = image.resize(img_size)\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Apply CLAHE\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    image = clahe.apply(image)\n",
        "\n",
        "    # Normalize\n",
        "    image = image.astype('float32') / 255.0\n",
        "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
        "    image = np.expand_dims(image, axis=0)   # Add batch dimension\n",
        "    return image\n",
        "\n",
        "def postprocess_mask(mask):\n",
        "    mask = (mask > 0.5).astype(np.uint8)\n",
        "    mask = mask.squeeze() * 255\n",
        "    return mask\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        image_bytes = await file.read()\n",
        "        image = preprocess_image(image_bytes)\n",
        "        prediction = model.predict(image)[0]\n",
        "        mask = postprocess_mask(prediction)\n",
        "\n",
        "        # Convert mask to bytes\n",
        "        _, img_encoded = cv2.imencode('.png', mask)\n",
        "        mask_bytes = img_encoded.tobytes()\n",
        "\n",
        "        return JSONResponse(content={\"message\": \"Success\"})\n",
        "    except Exception as e:\n",
        "        return JSONResponse(content={\"message\": f\"Error: {str(e)}\"}, status_code=500)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "id": "q5S-Z5GTrlBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit requests pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HHbnTvXrl4N",
        "outputId": "c96cb16b-657a-4859-e0f5-43ce2b202606"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# FAST API endpoint\n",
        "API_URL = \"http://localhost:8000/predict/\"\n",
        "\n",
        "st.title(\"Brain MRI Metastasis Segmentation\")\n",
        "st.write(\"Upload a Brain MRI image to get the metastasis segmentation.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an MRI image...\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display the uploaded image\n",
        "    image = Image.open(uploaded_file).convert('L')  # Convert to grayscale\n",
        "    st.image(image, caption='Uploaded MRI Image', use_column_width=True)\n",
        "\n",
        "    # Prepare the image for sending\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    img_bytes = buffered.getvalue()\n",
        "\n",
        "    # Send the image to the FAST API backend\n",
        "    st.write(\"Processing...\")\n",
        "    response = requests.post(API_URL, files={\"file\": img_bytes})\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        st.success(\"Segmentation Completed!\")\n",
        "        # For demonstration, we'll display the uploaded image as the mask\n",
        "        # Replace this with actual mask retrieval from the backend\n",
        "        # Example: Display the mask if returned as base64\n",
        "        # Here, assuming the backend sends back the mask image bytes\n",
        "        # Modify the backend to return the mask image in a suitable format\n",
        "    else:\n",
        "        st.error(\"Error in processing the image.\")\n"
      ],
      "metadata": {
        "id": "9k4HU1FqryxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py (Enhanced)\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import JSONResponse\n",
        "import uvicorn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Load the best model\n",
        "model = tf.keras.models.load_model('best_metastasis_segmentation_model.h5', compile=False)\n",
        "\n",
        "def preprocess_image(image_bytes, img_size=(256, 256)):\n",
        "    # Read image\n",
        "    image = Image.open(io.BytesIO(image_bytes)).convert('L')  # Convert to grayscale\n",
        "    image = image.resize(img_size)\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Apply CLAHE\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    image = clahe.apply(image)\n",
        "\n",
        "    # Normalize\n",
        "    image = image.astype('float32') / 255.0\n",
        "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
        "    image = np.expand_dims(image, axis=0)   # Add batch dimension\n",
        "    return image\n",
        "\n",
        "def postprocess_mask(mask):\n",
        "    mask = (mask > 0.5).astype(np.uint8) * 255\n",
        "    mask = mask.squeeze()\n",
        "    return mask\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        image_bytes = await file.read()\n",
        "        image = preprocess_image(image_bytes)\n",
        "        prediction = model.predict(image)[0]\n",
        "        mask = postprocess_mask(prediction)\n",
        "\n",
        "        # Convert mask to PNG\n",
        "        _, img_encoded = cv2.imencode('.png', mask)\n",
        "        mask_bytes = img_encoded.tobytes()\n",
        "        mask_base64 = base64.b64encode(mask_bytes).decode('utf-8')\n",
        "\n",
        "        return JSONResponse(content={\"mask\": mask_base64})\n",
        "    except Exception as e:\n",
        "        return JSONResponse(content={\"message\": f\"Error: {str(e)}\"}, status_code=500)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "id": "_6UxIUj0sIiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py (Enhanced)\n",
        "import streamlit as st\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# FAST API endpoint\n",
        "API_URL = \"http://localhost:8000/predict/\"\n",
        "\n",
        "st.title(\"Brain MRI Metastasis Segmentation\")\n",
        "st.write(\"Upload a Brain MRI image to get the metastasis segmentation.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an MRI image...\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Display the uploaded image\n",
        "    image = Image.open(uploaded_file).convert('L')  # Convert to grayscale\n",
        "    st.image(image, caption='Uploaded MRI Image', use_column_width=True)\n",
        "\n",
        "    # Prepare the image for sending\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    img_bytes = buffered.getvalue()\n",
        "\n",
        "    # Send the image to the FAST API backend\n",
        "    st.write(\"Processing...\")\n",
        "    response = requests.post(API_URL, files={\"file\": img_bytes})\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        mask_base64 = result.get(\"mask\", None)\n",
        "        if mask_base64:\n",
        "            mask_bytes = base64.b64decode(mask_base64)\n",
        "            mask_image = Image.open(io.BytesIO(mask_bytes))\n",
        "            st.image(mask_image, caption='Metastasis Segmentation Mask', use_column_width=True)\n",
        "        else:\n",
        "            st.error(\"Mask not found in the response.\")\n",
        "    else:\n",
        "        st.error(\"Error in processing the image.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWZk-xwsr5Pk",
        "outputId": "c4fa9987-3943-4d69-cf75-72a1d7283151"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-10-01 06:06:15.567 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.665 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-10-01 06:06:15.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.670 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.675 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.678 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-01 06:06:15.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}